{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fb99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 63.4898\n",
      "Epoch 1, Batch 100, Loss: 63.4898\n",
      "Epoch 1, Batch 200, Loss: 63.4898\n",
      "Epoch 1, Batch 300, Loss: 63.4898\n",
      "Epoch 1, Batch 400, Loss: 63.4898\n",
      "Epoch 1, Batch 500, Loss: 63.4898\n",
      "Epoch 1, Batch 600, Loss: 63.4898\n",
      "Epoch 1, Batch 700, Loss: 63.4898\n",
      "Epoch 1, Batch 800, Loss: 63.4898\n",
      "Epoch 1, Batch 900, Loss: 63.4898\n",
      "Epoch 2, Batch 0, Loss: 63.4898\n",
      "Epoch 2, Batch 100, Loss: 63.4898\n",
      "Epoch 2, Batch 200, Loss: 63.4898\n",
      "Epoch 2, Batch 300, Loss: 63.4898\n",
      "Epoch 2, Batch 400, Loss: 63.4898\n",
      "Epoch 2, Batch 500, Loss: 63.4898\n",
      "Epoch 2, Batch 600, Loss: 63.4898\n",
      "Epoch 2, Batch 700, Loss: 63.4898\n",
      "Epoch 2, Batch 800, Loss: 63.4898\n",
      "Epoch 2, Batch 900, Loss: 63.4898\n",
      "Epoch 3, Batch 0, Loss: 63.4898\n",
      "Epoch 3, Batch 100, Loss: 63.4898\n",
      "Epoch 3, Batch 200, Loss: 63.4898\n",
      "Epoch 3, Batch 300, Loss: 63.4898\n",
      "Epoch 3, Batch 400, Loss: 63.4898\n",
      "Epoch 3, Batch 500, Loss: 63.4898\n",
      "Epoch 3, Batch 600, Loss: 63.4898\n",
      "Epoch 3, Batch 700, Loss: 63.4898\n",
      "Epoch 3, Batch 800, Loss: 63.4898\n",
      "Epoch 3, Batch 900, Loss: 63.4898\n",
      "Test Accuracy: 2.84%\n",
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x128 and 64x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 256\u001b[39m\n\u001b[32m    254\u001b[39m     images, labels = images.to(device), labels.to(device)\n\u001b[32m    255\u001b[39m     target = F.one_hot(labels, num_classes=\u001b[32m10\u001b[39m).float()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     e1, e2, e3 = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_predictive_coding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m     total_loss += e3  \u001b[38;5;66;03m# Track output layer error\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Output Layer Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 231\u001b[39m, in \u001b[36mPredictiveCodingNet.train_predictive_coding\u001b[39m\u001b[34m(self, x, target, iterations, lr)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# Compute prediction errors layer by layer (simplified)\u001b[39;00m\n\u001b[32m    230\u001b[39m error3 = target - z3\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m error2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43merror3\u001b[49m * (z2 > \u001b[32m0\u001b[39m)\n\u001b[32m    232\u001b[39m error1 = \u001b[38;5;28mself\u001b[39m.l1.linear.weight.T @ error2 * (z1 > \u001b[32m0\u001b[39m)\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Update weights with prediction errors\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (256x128 and 64x10)"
     ]
    }
   ],
   "source": [
    "# Introduction to Predictive Coding Models: MNIST Example\n",
    "\n",
    "# This notebook demonstrates a minimal three-layer predictive coding model for image classification using the MNIST dataset. Each layer predicts the next, computes prediction errors, and updates its states and weights accordingly. Lateral connections are included for richer feature interactions.\n",
    "\n",
    "# ---\n",
    "\n",
    "## 1. Import Libraries and Load Data\n",
    "\n",
    "# ```python\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "## 2. Data Preprocessing\n",
    "\n",
    "# ```python\n",
    "# Download and load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Use a smaller subset for faster training (for demonstration)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "## 3. Predictive Coding Model Definition\n",
    "\n",
    "### Model Structure\n",
    "\n",
    "# - **Input Layer:** 784 units (28x28 pixels)\n",
    "# - **Hidden Layer:** 256 units\n",
    "# - **Output Layer:** 10 units (digits 0-9)\n",
    "# - **Lateral Connections:** Within hidden layer\n",
    "\n",
    "# ```python\n",
    "class PredictiveCodingModel:\n",
    "    def __init__(self, input_size=784, hidden_size=256, output_size=10, lr=1e-3):\n",
    "        # Feedforward weights\n",
    "        self.W1 = np.random.randn(hidden_size, input_size) * 0.1\n",
    "        self.W2 = np.random.randn(output_size, hidden_size) * 0.1\n",
    "        # Lateral weights (hidden layer)\n",
    "        self.L1 = np.eye(hidden_size) * 0.01  # Small lateral weights\n",
    "        # States\n",
    "        self.x1 = np.zeros((hidden_size, 1))\n",
    "        self.x2 = np.zeros((output_size, 1))\n",
    "        # Learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0, keepdims=True)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        # x0: input (784, 1)\n",
    "        # Predict hidden state\n",
    "        pred_x1 = self.sigmoid(self.W1 @ x0 + self.L1 @ self.x1)\n",
    "        # Predict output\n",
    "        pred_x2 = self.softmax(self.W2 @ pred_x1)\n",
    "        return pred_x1, pred_x2\n",
    "\n",
    "    def compute_errors(self, x0, x1, x2, y):\n",
    "        # Prediction errors\n",
    "        e0 = x0 - self.W1.T @ x1  # Input error\n",
    "        e1 = x1 - self.sigmoid(self.W1 @ x0 + self.L1 @ x1)  # Hidden error\n",
    "        e2 = x2 - y  # Output error (y is one-hot)\n",
    "        return e0, e1, e2\n",
    "\n",
    "    def update_states(self, x0, x1, x2, y, e0, e1, e2):\n",
    "        # Update hidden state (x1)\n",
    "        dx1 = self.W1 @ e0 + self.L1 @ e1 - e1\n",
    "        x1 += self.lr * dx1\n",
    "        # Update output state (x2)\n",
    "        dx2 = -e2\n",
    "        x2 += self.lr * dx2\n",
    "        return x1, x2\n",
    "\n",
    "    def update_weights(self, x0, x1, x2, e0, e1, e2):\n",
    "        # Update feedforward weights\n",
    "        self.W1 += self.lr * (np.outer(e1, x0))\n",
    "        self.W2 += self.lr * (np.outer(e2, x1))\n",
    "        # Update lateral weights (hidden)\n",
    "        self.L1 += self.lr * (np.outer(e1, x1))\n",
    "\n",
    "    def predict(self, x0):\n",
    "        x1 = self.sigmoid(self.W1 @ x0 + self.L1 @ np.zeros_like(self.x1))\n",
    "        x2 = self.softmax(self.W2 @ x1)\n",
    "        return np.argmax(x2)\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "## 4. Training Loop\n",
    "\n",
    "# ```python\n",
    "def one_hot(label, num_classes=10):\n",
    "    vec = np.zeros((num_classes, 1))\n",
    "    vec[label] = 1\n",
    "    return vec\n",
    "\n",
    "model = PredictiveCodingModel()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.view(-1, 28*28).numpy()\n",
    "        target = target.numpy()\n",
    "        for i in range(data.shape[0]):\n",
    "            x0 = data[i].reshape(-1, 1)\n",
    "            y = one_hot(target[i])\n",
    "            # Initialize states\n",
    "            x1 = np.zeros((256, 1))\n",
    "            x2 = np.zeros((10, 1))\n",
    "            # Iterative inference (simulate prediction-error minimization)\n",
    "            for _ in range(5):\n",
    "                pred_x1, pred_x2 = model.forward(x0)\n",
    "                e0, e1, e2 = model.compute_errors(x0, x1, x2, y)\n",
    "                x1, x2 = model.update_states(x0, x1, x2, y, e0, e1, e2)\n",
    "            # Update weights after inference\n",
    "            model.update_weights(x0, x1, x2, e0, e1, e2)\n",
    "            # Loss (sum of squared errors)\n",
    "            total_loss += np.sum(e2**2)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {total_loss/(batch_idx+1):.4f}\")\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "## 5. Evaluation\n",
    "\n",
    "# ```python\n",
    "correct = 0\n",
    "total = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.view(-1, 28*28).numpy()\n",
    "    target = target.numpy()\n",
    "    for i in range(data.shape[0]):\n",
    "        x0 = data[i].reshape(-1, 1)\n",
    "        pred = model.predict(x0)\n",
    "        if pred == target[i]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "# ```\n",
    "\n",
    "# ---\n",
    "\n",
    "## 6. Summary\n",
    "\n",
    "# This notebook implemented a minimal predictive coding model with three layers and lateral connections for MNIST classification. Each layer predicts the next, computes errors, and updates its states and weights to minimize prediction error. The model demonstrates the core logic of predictive coding and achieves basic classification accuracy.\n",
    "\n",
    "# ---\n",
    "\n",
    "# **Note:** This is a minimal, educational implementation. For higher accuracy, use more advanced architectures and optimization techniques.# Predictive Coding Model for MNIST Classification\n",
    "\n",
    "# --- Cell 1: Install and Import Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Cell 2: Load and Preprocess MNIST Data ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize MNIST\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# --- Cell 3: Define Predictive Coding Layer ---\n",
    "class PredictiveCodingLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PredictiveCodingLayer, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.state = torch.zeros(output_size).to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        prediction = self.linear(input)\n",
    "        return prediction\n",
    "\n",
    "    def update(self, prediction, target, learning_rate=0.01):\n",
    "        error = target - prediction  # Prediction error\n",
    "        self.linear.weight.data += learning_rate * torch.outer(error, self.linear.input)\n",
    "        self.linear.bias.data += learning_rate * error\n",
    "        return error\n",
    "\n",
    "# --- Cell 4: Full Predictive Coding Network ---\n",
    "class PredictiveCodingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PredictiveCodingNet, self).__init__()\n",
    "        self.l1 = PredictiveCodingLayer(28*28, 256)\n",
    "        self.l2 = PredictiveCodingLayer(256, 128)\n",
    "        self.l3 = PredictiveCodingLayer(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        z1 = F.relu(self.l1(x))\n",
    "        z2 = F.relu(self.l2(z1))\n",
    "        z3 = self.l3(z2)\n",
    "        return z1, z2, z3\n",
    "\n",
    "    def train_predictive_coding(self, x, target, iterations=1, lr=0.01):\n",
    "        x = x.view(-1, 28*28)\n",
    "        z1, z2, z3 = self.forward(x)\n",
    "\n",
    "        # Compute prediction errors layer by layer (simplified)\n",
    "        error3 = target - z3\n",
    "        error2 = self.l2.linear.weight.T @ error3 * (z2 > 0)\n",
    "        error1 = self.l1.linear.weight.T @ error2 * (z1 > 0)\n",
    "\n",
    "        # Update weights with prediction errors\n",
    "        self.l3.linear.weight.data += lr * torch.matmul(error3.T, z2)\n",
    "        self.l2.linear.weight.data += lr * torch.matmul(error2.T, z1)\n",
    "        self.l1.linear.weight.data += lr * torch.matmul(error1.T, x)\n",
    "\n",
    "        self.l3.linear.bias.data += lr * error3.sum(0)\n",
    "        self.l2.linear.bias.data += lr * error2.sum(0)\n",
    "        self.l1.linear.bias.data += lr * error1.sum(0)\n",
    "\n",
    "        return error1.norm().item(), error2.norm().item(), error3.norm().item()\n",
    "\n",
    "# --- Cell 5: Train Model ---\n",
    "model = PredictiveCodingNet().to(device)\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        target = F.one_hot(labels, num_classes=10).float()\n",
    "        e1, e2, e3 = model.train_predictive_coding(images, target, lr=lr)\n",
    "        total_loss += e3  # Track output layer error\n",
    "    print(f\"Epoch {epoch+1} - Output Layer Error: {total_loss:.4f}\")\n",
    "\n",
    "# --- Cell 6: Evaluate Accuracy ---\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            _, _, output = model.forward(images)\n",
    "            preds = output.argmax(dim=1).cpu()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "acc = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
